{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trashmanagement.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilalithaveerubhotla/CMPE_258/blob/master/trashmanagement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu4nYpLnCZf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy\n",
        "import glob\n",
        "import pylab as plt\n",
        "import os\n",
        "\n",
        "# importing libraries\n",
        "from matplotlib import pyplot\n",
        "from keras import datasets\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D,Dense,Dropout,SpatialDropout2D\n",
        "from keras.models  import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
        "import random,os,glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from kerastuner.tuners import RandomSearch\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "from keras.utils import print_summary, to_categorical\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
        "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
        "from datetime import datetime\n",
        "%load_ext tensorboard\n",
        "# %reload_ext tensorboard\n",
        "%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Vn26ogiJ8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOnuRYF2nENA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/garbage-classification.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsilLSTEiJ_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing and deriving the training images and labelling them\n",
        "trash_images = []\n",
        "labels = [] \n",
        "for fruit_dir_path in glob.glob(\"/content/garbage classification/Garbage classification/*/\"):\n",
        "    fruit_label = fruit_dir_path.split(\"/\")[4]\n",
        "    for image_path in glob.glob(os.path.join(fruit_dir_path, \"*.jpg\")):\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "        \n",
        "        image = cv2.resize(image, (70, 70))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        \n",
        "        trash_images.append(image)\n",
        "        labels.append(fruit_label)\n",
        "trash_images = np.array(trash_images)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrL6cadI8pi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58zinSfGiKEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_to_id_dict = {v:i for i,v in enumerate(np.unique(labels))}\n",
        "id_to_label_dict = {v: k for k, v in label_to_id_dict.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUHQ-MzfiKGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_label_id = np.array([label_to_id_dict[i] for i in labels])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ffvgZ_NlIvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id_to_label_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zgIpJlvlQwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Train_data shape......:\",trash_images.shape)\n",
        "print(\"Labels shape..........:\",training_label_id.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39KRzsDFlwWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(trainX, testX, trainY, testY) = train_test_split(trash_images, training_label_id, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi-vklch6tc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "now = datetime.now()\n",
        "logdir = \"logs/trash_images/\" + now.strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
        "with file_writer.as_default():\n",
        "  tf.summary.image(\"Training data\", np.reshape(trainX[0:3],(-2,70,70,3)), step=0)\n",
        "file_writer.set_as_default()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAr0S6hl7fBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/trash_images/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh4E3IZe9q20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_path = '/content/garbage classification/Garbage classification'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZJCgLhj9wuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_list = glob.glob(os.path.join(dir_path, '*/*.jpg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJj0PMHB90EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(img_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jNetNoEQBwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvbXWwe6qLp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# img_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiOmJhAdbuUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, img_path in enumerate(random.sample(img_list, 6)):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img = image.img_to_array(img, dtype=np.uint8)\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(img.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5268yDn9h_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_images():\n",
        "  train=ImageDataGenerator(horizontal_flip=True,\n",
        "                         vertical_flip=True,\n",
        "                         validation_split=0.1,\n",
        "                         rescale=1./255,\n",
        "                         shear_range = 0.1,\n",
        "                         zoom_range = 0.1,\n",
        "                         width_shift_range = 0.1,\n",
        "                         height_shift_range = 0.1,)\n",
        "\n",
        "  test=ImageDataGenerator(rescale=1/255,\n",
        "                        validation_split=0.1)\n",
        "\n",
        "  train_generator=train.flow_from_directory(dir_path,\n",
        "                                          target_size=(300,300),\n",
        "                                          batch_size=32,\n",
        "                                          class_mode='categorical',\n",
        "                                          subset='training')\n",
        "\n",
        "  test_generator=test.flow_from_directory(dir_path,\n",
        "                                        target_size=(300,300),\n",
        "                                        batch_size=32,\n",
        "                                        class_mode='categorical',\n",
        "                                        subset='validation')\n",
        "\n",
        "  validation_generator = test.flow_from_directory(\n",
        "    dir_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    seed=0\n",
        ")\n",
        "\n",
        "  labels = (train_generator.class_indices)\n",
        "  print(labels)\n",
        "\n",
        "  labels = dict((v,k) for k,v in labels.items())\n",
        "  print(labels)\n",
        "  return train_generator, test_generator,validation_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXE9QHzk-HkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image_batch, label_batch in train_generator:\n",
        "  break\n",
        "image_batch.shape, label_batch.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Z0QT_D-LKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (train_generator.class_indices)\n",
        "\n",
        "Labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(Labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58UtoGdp-NXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "#Convolution blocks\n",
        "\n",
        "model.add(Conv2D(32,(3,3), padding='same',input_shape=(300,300,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2)) \n",
        "#model.add(SpatialDropout2D(0.5)) # No accuracy\n",
        "\n",
        "model.add(Conv2D(64,(3,3), padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2)) \n",
        "#model.add(SpatialDropout2D(0.5))\n",
        "\n",
        "model.add(Conv2D(32,(3,3), padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2)) \n",
        "\n",
        "#Classification layers\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64,activation='relu'))\n",
        "#model.add(SpatialDropout2D(0.5))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(6,activation='softmax'))\n",
        "\n",
        "filepath=\"/content/trained_model.h5\"\n",
        "checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoRpItrF-RsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adnJdTFa-WHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc']) # RMS PROP - No accuracy\n",
        "\n",
        "#es=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbjEDQoX-Zlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=10,\n",
        "                              steps_per_epoch=2276//32,\n",
        "                              validation_data=test_generator,\n",
        "                              validation_steps=251//32,\n",
        "                              workers = 4,\n",
        "                              callbacks=callbacks_list) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8LDWsJdd78B",
        "colab_type": "text"
      },
      "source": [
        "## Simple CNN Fine Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO57c6gLeBQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "#Convolution blocks\n",
        "\n",
        "model.add(Conv2D(32,(3,3), padding='same',input_shape=(300,300,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2)) \n",
        "#model.add(SpatialDropout2D(0.5)) # No accuracy\n",
        "\n",
        "model.add(Conv2D(64,(3,3), padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2)) \n",
        "#model.add(SpatialDropout2D(0.5))\n",
        "\n",
        "model.add(Conv2D(32,(3,3), padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2)) \n",
        "\n",
        "#Classification layers\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64,activation='relu'))\n",
        "#model.add(SpatialDropout2D(0.5))\n",
        "\n",
        "model.add(Dense(6,activation='softmax'))\n",
        "\n",
        "filepath=\"/content/trained_model.h5\"\n",
        "checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byI9r8tLd7Q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNjgc3cJfAvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBayJPlVfELD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(train_generator, epochs=150, steps_per_epoch=2276//32,validation_data=test_generator,\n",
        "                    validation_steps=251//32,callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "260gF6dn80ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p classifier1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc_NTUenzBFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'classifier1.h5'\n",
        "model.save('/content/trained_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIVHc77rzqoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"/content/model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpWbNMoSoYX7",
        "colab_type": "text"
      },
      "source": [
        "### VGG16 TRANSFER LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWV_6F0foA7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzBlsFmvmCqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = VGG16()\n",
        "plot_model(model, to_file='vgg.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC6Hj4Y1ocKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = VGG16()\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2B6Mq-2pDFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "# load an image from file\n",
        "image = load_img('/content/garbage classification/Garbage classification/paper/paper357.jpg', target_size=(224, 224))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY1N2X5upk_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "# convert the image pixels to a numpy array\n",
        "image = img_to_array(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx9B1PJ2qgSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape data for the model\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pyd6eH8qitp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "# prepare the image for the VGG model\n",
        "image = preprocess_input(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3t7cMt2qlv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yhat = model.predict(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwRh7qmfqpXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import decode_predictions\n",
        "# convert the probabilities to class labels\n",
        "label = decode_predictions(yhat)\n",
        "# retrieve the most likely result, e.g. highest probability\n",
        "label = label[0][0]\n",
        "# print the classification\n",
        "print('%s (%.2f%%)' % (label[1], label[2]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN8InFBIQHrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/keras-pretrained-models.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yWWGlO4q1FQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = {\n",
        "    \"train\": ImageDataGenerator(\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        rescale=1. / 255,\n",
        "        validation_split=0.1,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        rotation_range=30,\n",
        "    ).flow_from_directory(\n",
        "        directory=dir_path,\n",
        "        target_size=(300, 300),\n",
        "        subset='training',\n",
        "    ),\n",
        "\n",
        "    \"valid\": ImageDataGenerator(\n",
        "        rescale=1 / 255,\n",
        "        validation_split=0.1,\n",
        "    ).flow_from_directory(\n",
        "        directory=dir_path,\n",
        "        target_size=(300, 300),\n",
        "        subset='validation',\n",
        "    ),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui2LAaJTbN8_",
        "colab_type": "text"
      },
      "source": [
        "## INCEPTION V3 TOP Notch Transfer Learned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNlS8azOO_Ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers, losses\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import pickle\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8nHjcAqP_yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = InceptionV3(weights=None, include_top=False, input_shape=(300, 300, 3))\n",
        "base_model.load_weights('/content/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "base_model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB9zgAD8P_11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.15),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "opt = optimizers.nadam(lr=0.0001)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "batch_size = 200\n",
        "epochs = 10\n",
        "train_generator = gen[\"train\"]\n",
        "valid_generator = gen[\"valid\"]\n",
        "\n",
        "steps_per_epoch = train_generator.n // batch_size\n",
        "validation_steps = valid_generator.n // batch_size\n",
        "\n",
        "filepath = \"model_{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
        "checkpoint1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint1]\n",
        "history = model.fit_generator(generator=train_generator, epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
        "                              validation_data=valid_generator, validation_steps=validation_steps,\n",
        "                              callbacks=callbacks_list)\n",
        "with open('trainHistoryDict.txt', 'wb') as file_pi:\n",
        "    pickle.dump(history.history, file_pi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fZO0Cc7aYTX",
        "colab_type": "text"
      },
      "source": [
        "## RESNET 50 top notch Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykL4g8R-QzMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers, losses\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import pickle\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXeg8Vkyaq2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = VGG16(weights=None, include_top=False, input_shape=(300, 300, 3))\n",
        "base_model.load_weights('/content/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "base_model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0dffqKxa6_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.15),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "opt = optimizers.nadam(lr=0.0001)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "batch_size = 200\n",
        "epochs = 10\n",
        "train_generator = gen[\"train\"]\n",
        "valid_generator = gen[\"valid\"]\n",
        "\n",
        "steps_per_epoch = train_generator.n // batch_size\n",
        "validation_steps = valid_generator.n // batch_size\n",
        "\n",
        "filepath = \"model_{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
        "checkpoint1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint1]\n",
        "history = model.fit_generator(generator=train_generator, epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
        "                              validation_data=valid_generator, validation_steps=validation_steps,\n",
        "                              callbacks=callbacks_list)\n",
        "with open('trainHistoryDict.txt', 'wb') as file_pi:\n",
        "    pickle.dump(history.history, file_pi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKJZmpE6ceF4",
        "colab_type": "text"
      },
      "source": [
        "## MobileNet Transfer Learned Top Notch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTLODoUbbBPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SHAPE = (224,224,3)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False, \n",
        "                                               weights='imagenet')\n",
        "base_model.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LShYTGqcrJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(6, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ou3GxDScwyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001), #Adam(), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2CDfFQ-cz97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 50\n",
        "steps_per_epoch = train_generator.n // batch_size\n",
        "validation_steps = validation_generator.n // batch_size\n",
        "\n",
        "history = model.fit_generator(train_generator, \n",
        "                              steps_per_epoch = steps_per_epoch,\n",
        "                              epochs=epochs, \n",
        "                              workers=4,\n",
        "                              validation_data=validation_generator, \n",
        "                              validation_steps=validation_steps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni2p9o2Vc2qT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/pjreddie/darknet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F2Hpl4Jmg3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd darknet/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf7Ud4DDmkQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!make"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrETc8Zjml1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIvSaLFLoiGh",
        "colab_type": "text"
      },
      "source": [
        "## Pytorch implemented transfer learned  RCNN RESNET 50 model for Object Detection"
      ]
    }
  ]
}